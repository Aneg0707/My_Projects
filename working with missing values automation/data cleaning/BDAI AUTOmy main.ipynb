{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad00d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import json\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4200eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\Hennadii\\Desktop\\BDAI club\\automation python\\CustSeg.Train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf6d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:  CustSeg.Train \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Data - read csv file and save as dataframe\n",
    "# if the files is csv format, use pd.read_csv()\n",
    "if filepath.endswith('.csv'):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # check if the files is excel format, use pd.read_excel() to read the first tab of the excel file\n",
    "elif filepath.endswith('.xlsx'):\n",
    "    df = pd.read_excel(filepath, sheet_name=0)\n",
    "\n",
    "\n",
    "# save file name wih extension into variable\n",
    "filename = os.path.basename(filepath)\n",
    "# remove extension from filename\n",
    "filename = os.path.splitext(filename)[0]\n",
    "print(\"File name: \", filename,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c140f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "replaceType = 'median' # use 'mean' or 'median' to replace missing values\n",
    "alpha = 0.05 # variables for statistical Shapiro-Wilk test for normality, as \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ae528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n",
      "None \n",
      "\n",
      "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
      "0  462809    Male           No   22        No     Healthcare              1.0   \n",
      "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
      "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
      "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
      "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
      "\n",
      "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
      "0            Low          4.0  Cat_4            D  \n",
      "1        Average          3.0  Cat_4            A  \n",
      "2            Low          1.0  Cat_6            B  \n",
      "3           High          2.0  Cat_6            B  \n",
      "4           High          6.0  Cat_6            A   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print info of data\n",
    "print(df.info(),\"\\n\")\n",
    "print(df.head(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ffd689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "ID                   0\n",
      "Gender               0\n",
      "Ever_Married       140\n",
      "Age                  0\n",
      "Graduated           78\n",
      "Profession         124\n",
      "Work_Experience    829\n",
      "Spending_Score       0\n",
      "Family_Size        335\n",
      "Var_1               76\n",
      "Segmentation         0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print number of missing values\n",
    "print(\"Number of missing values:\")\n",
    "print(df.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3be802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a list of boolean columns\n",
    "boolcols = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == \"bool\":\n",
    "        boolcols.append(i)\n",
    "        \n",
    "# create a list of boolean columns with missing values\n",
    "boolcols_missing = []\n",
    "for i in boolcols:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        boolcols_missing.append(i)\n",
    "        \n",
    "# if number of missing values is less than 5%, replace with mode, otherwise replace with not_available\n",
    "for i in boolcols_missing:\n",
    "    print(\"\\n for boolean columns, If the number of missing values is less than 5%, replace with mode, otherwise replace with 'not_available': \\n\")\n",
    "    if df[i].isnull().sum()/df.shape[0] < 0.05:\n",
    "        df[i].fillna(df[i].mode()[0], inplace=True)\n",
    "        print(i, \"has missing values filled with mode\")\n",
    "    else:\n",
    "        # replace missing values with NA\n",
    "        df[i].fillna('not_available', inplace=True)\n",
    "        print(i, \"has missing values more than 5%, replaced with 'not_available'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052a83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data volume is too large, missing values will be replaced with mean or median automically: median \n",
      "\n",
      "Replaced missing values in column:  Work_Experience  with  median\n",
      "Replaced missing values in column:  Family_Size  with  median\n"
     ]
    }
   ],
   "source": [
    "#### Create a list of Numerical columns (int and float (and boolean?))\n",
    "numcols = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != \"object\":\n",
    "        numcols.append(i)\n",
    "\n",
    "# create a list of numerical columns with missing values\n",
    "numcols_missing = []\n",
    "for i in numcols:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        numcols_missing.append(i)\n",
    "\n",
    "# check if data volume >5000 or not\n",
    "if df.shape[0] > 5000:\n",
    "    print(\"Data volume is too large, missing values will be replaced with mean or median automically:\" , replaceType, \"\\n\")\n",
    "    # replace missing values with mean or median\n",
    "    if replaceType == 'mean':\n",
    "        for i in numcols_missing:\n",
    "                df[i].fillna(df[i].mean(), inplace=True)\n",
    "                print(\"Replaced missing values in column: \", i, \" with \", replaceType)\n",
    "    elif replaceType == 'median':\n",
    "        for i in numcols_missing:\n",
    "                df[i].fillna(df[i].median(), inplace=True)\n",
    "                print(\"Replaced missing values in column: \", i, \" with \", replaceType)\n",
    "else:\n",
    "    print(\"Data volume is\", df.shape[0],\", missing values will be replaced with mean or median based on statistical Shapiro-Wilk test for normality\", \"\\n\")\n",
    "\n",
    "    ## the function to Determine Shapiro-Wilk p-value < alpha with a function:\n",
    "    def shapiro_check(x, alpha):\n",
    "        p = shapiro(x).pvalue\n",
    "        if p > alpha:\n",
    "            return(False)\n",
    "        else:\n",
    "            return(True)\n",
    "\n",
    "    # if the numerical column is normally distributed, replace missing values with mean, otherwise with median  \n",
    "    for i in numcols_missing:\n",
    "        if shapiro_check(df[i], alpha) == False:\n",
    "            print(i, \"is not normally distributed, filled with median\")\n",
    "            df[i].fillna(df[i].median(), inplace=True)\n",
    "        else:\n",
    "            print(i, \"is normally distributed, filled with mean\")\n",
    "            df[i].fillna(df[i].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1c5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For categorical columns, if the number of missing values is less than 5%, replace with mode, otherwise replace with 'not_available': \n",
      "\n",
      "Ever_Married has missing values filled with mode\n",
      "Graduated has missing values filled with mode\n",
      "Profession has missing values filled with mode\n",
      "Var_1 has missing values filled with mode\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# Create a list of Categorical columns\n",
    "catcols = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == \"object\":\n",
    "        catcols.append(i)\n",
    "\n",
    "# if column contains only one unique value, drop it\n",
    "for i in catcols:\n",
    "    if len(df[i].unique()) == 1:\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "        print(i, \"is dropped because it contains only one unique value\")\n",
    "\n",
    "# create a list of categorical columns with missing values\n",
    "catcols_missing = []\n",
    "for i in catcols:\n",
    "    if df[i].isnull().sum() > 0:\n",
    "        catcols_missing.append(i)\n",
    "\n",
    "# if number of missing values is less than 5%, replace with mode, otherwise replace with not_available\n",
    "print(\"\\nFor categorical columns, if the number of missing values is less than 5%, replace with mode, otherwise replace with 'not_available': \\n\")\n",
    "\n",
    "for i in catcols_missing:\n",
    "    if df[i].isnull().sum()/df.shape[0] < 0.05:\n",
    "        df[i].fillna(df[i].mode()[0], inplace=True)\n",
    "        print(i, \"has missing values filled with mode\")\n",
    "    else:\n",
    "        # replace missing values with NA\n",
    "        df[i].fillna('not_available', inplace=True)\n",
    "        print(i, \"has missing values more than 5%, replaced with 'not_available'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5a0cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New dictionary file will be created:\n",
      "\n",
      "Gender is replaced with numeric values\n",
      "Ever_Married is replaced with numeric values\n",
      "Graduated is replaced with numeric values\n",
      "Profession is replaced with numeric values\n",
      "Spending_Score is replaced with numeric values\n",
      "Var_1 is replaced with numeric values\n",
      "Segmentation is replaced with numeric values\n",
      "\n",
      "The dictionary of categories: \n",
      "\n",
      "{\n",
      " \"Gender\": {\n",
      "  \"Male\": 0,\n",
      "  \"Female\": 1\n",
      " },\n",
      " \"Ever_Married\": {\n",
      "  \"No\": 0,\n",
      "  \"Yes\": 1\n",
      " },\n",
      " \"Graduated\": {\n",
      "  \"No\": 0,\n",
      "  \"Yes\": 1\n",
      " },\n",
      " \"Profession\": {\n",
      "  \"Healthcare\": 0,\n",
      "  \"Engineer\": 1,\n",
      "  \"Lawyer\": 2,\n",
      "  \"Entertainment\": 3,\n",
      "  \"Artist\": 4,\n",
      "  \"Executive\": 5,\n",
      "  \"Doctor\": 6,\n",
      "  \"Homemaker\": 7,\n",
      "  \"Marketing\": 8\n",
      " },\n",
      " \"Spending_Score\": {\n",
      "  \"Low\": 0,\n",
      "  \"Average\": 1,\n",
      "  \"High\": 2\n",
      " },\n",
      " \"Var_1\": {\n",
      "  \"Cat_4\": 0,\n",
      "  \"Cat_6\": 1,\n",
      "  \"Cat_7\": 2,\n",
      "  \"Cat_3\": 3,\n",
      "  \"Cat_1\": 4,\n",
      "  \"Cat_2\": 5,\n",
      "  \"Cat_5\": 6\n",
      " },\n",
      " \"Segmentation\": {\n",
      "  \"D\": 0,\n",
      "  \"A\": 1,\n",
      "  \"B\": 2,\n",
      "  \"C\": 3\n",
      " }\n",
      "}\n",
      "\n",
      "Dictionary file:  CustSeg.Train_category_dict.json is created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"        \\n## Find a way to assign missing values to '0' ?\\n## then map all categorical to numeric not '0' ?\\n\\n## Next Step: How to look up dictionary of recoded values, after analysis ?\\n## Is it possible to add 1 to all factors AND the dictionary, to avoid 0s ?\\n##      - would adding +1 be necessary or relevant?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 7. Transfer Categorical Columns to Numeric\n",
    "\"\"\"\n",
    "# pd.get_dummies()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/411336/how-many-dummy-variables-should-we-include-in-our-multiple-linear-regression-ana\n",
    "\n",
    "# Rule of Thumb: We should have at least 15 subjects per parameter.\n",
    "# If using dummies we should detect whether the number of dummies would exceed\n",
    "# a reasonable number and choose some other method.\n",
    "# \n",
    "# Following code to propose a method of recoding categorical values to numeric \n",
    "# values with pd.factorize()\n",
    "\n",
    "# Using pd.factorize reassign all categorical values to a numeric\n",
    "# Keep the key-value pairs in a dictionary\n",
    "# Use the dictionary to replace the categorical values with the numeric values\n",
    "\n",
    "# Using pd.factorize reassign all categorical values to a numeric\n",
    "# Keep the key-value pairs in a dictionary\n",
    "\"\"\"\n",
    "# convert boolean columns to numeric\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == \"bool\":\n",
    "        df[i] = df[i].astype(int)\n",
    "        print(i, \"is converted from boolean to numeric\")\n",
    "\n",
    "# check if there exists a disctionary file\n",
    "if os.path.isfile(os.path.join(os.path.dirname(filepath), filename + '_category_dict.json')):\n",
    "    # if yes, read the dictionary file\n",
    "    with open(os.path.join(os.path.dirname(filepath), filename + '_category_dict.json'), 'r') as f:\n",
    "        category_dict = json.load(f)\n",
    "    print(\"\\nDictionary file is loaded: \", filename + '_category_dict.json', \"\\n\")\n",
    "\n",
    "    # replace categorical values with numeric values\n",
    "    for i in catcols:\n",
    "        df[i] = df[i].map(category_dict[i])\n",
    "        print(i, \"is replaced with numeric values\")\n",
    "else:\n",
    "    # if no, create a new dictionary\n",
    "    category_dict = {}\n",
    "    print(\"\\nNew dictionary file will be created:\\n\")\n",
    "\n",
    "    # Loop through columns and apply pd.factorize to each\n",
    "    for i in catcols:\n",
    "        # Get the unique values in the column and save into dictionary, sorted by key\n",
    "        category_dict[i] = dict(enumerate(df[i].unique()))\n",
    "        # swap the key and value in the dictionary\n",
    "        category_dict[i] = {value:key for key,value in category_dict[i].items()}\n",
    "\n",
    "        # Recode the values in the column\n",
    "        # # With sort=True, the uniques will be sorted, and codes will be shuffled so that the relationship is the maintained.\n",
    "        df[i] = pd.factorize(df[i], sort=True)[0]\n",
    "        print(i, \"is replaced with numeric values\")\n",
    "    \n",
    "    # Print the dictionary of categories\n",
    "    print(\"\\nThe dictionary of categories: \\n\")\n",
    "    print(json.dumps(category_dict, indent=1))\n",
    "    \n",
    "     # save the dictionary into json file, to the same folder as the data file\n",
    "    with open(os.path.join(os.path.dirname(filepath), filename + '_category_dict.json'), 'w') as f:\n",
    "        f.write(json.dumps(category_dict, indent=1))\n",
    "    print(\"\\nDictionary file: \", filename + '_category_dict.json' ,\"is created\")\n",
    "\n",
    "\"\"\"        \n",
    "## Find a way to assign missing values to '0' ?\n",
    "## then map all categorical to numeric not '0' ?\n",
    "\n",
    "## Next Step: How to look up dictionary of recoded values, after analysis ?\n",
    "## Is it possible to add 1 to all factors AND the dictionary, to avoid 0s ?\n",
    "##      - would adding +1 be necessary or relevant?\"\"\"\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0c5c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recoded DataFrame:\n",
      "        ID  Gender  Ever_Married  Age  Graduated  Profession  Work_Experience  \\\n",
      "0  462809       1             0   22          0           5              1.0   \n",
      "1  462643       0             1   38          1           2              1.0   \n",
      "2  466315       0             1   67          1           2              1.0   \n",
      "3  461735       1             1   67          1           7              0.0   \n",
      "4  462669       0             1   40          1           3              1.0   \n",
      "\n",
      "   Spending_Score  Family_Size  Var_1  Segmentation  \n",
      "0               2          4.0      3             3  \n",
      "1               0          3.0      3             0  \n",
      "2               2          1.0      5             1  \n",
      "3               1          2.0      5             1  \n",
      "4               1          6.0      5             0  \n",
      "\n",
      "Recoded dataframe saved to CustSeg.Train_Recoded.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review the recoded dataframe\n",
    "print(\"\\nRecoded DataFrame:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9e9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recoded dataframe saved to CustSeg.Train_Recoded.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the recoded dataframe to a csv file with the name + \"Recoded\" as the original file, to the same folder as the data file\n",
    "df.to_csv(os.path.join(os.path.dirname(filepath), filename + \"_Recoded.csv\"), index=False)\n",
    "print(\"\\nRecoded dataframe saved to\", filename + \"_Recoded.csv\", \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
